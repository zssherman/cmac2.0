{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask demo notebook\n",
    "\n",
    "This notebook shows a demonstration of how to use dask and CMAC2.0 on a JupyterHub node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import dask.bag as db\n",
    "import pyart\n",
    "import importlib\n",
    "import netCDF4\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from cmac import cmac, quicklooks, get_sounding_times, get_sounding_file_name, config\n",
    "from IPython.display import Image, display\n",
    "from dask_jobqueue import PBSCluster\n",
    "from datetime import datetime\n",
    "from distributed import Client\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client, metrics, wait\n",
    "# wait for jobs to arrive, depending on the queue, this may take some time\n",
    "import dask.array as da\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler, progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subroutine, will do both the processing and plotting for one radar file. A more sophisicated version of this is contained within the cmac_dask script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmac_and_plotting(radar_file_path, cmac_config, sonde_times,\n",
    "                          sounding_files, clutter_file_path, \n",
    "                          out_path, img_directory, sweep=0, dd_lobes=False):\n",
    "    \"\"\" For dask we need the radar plotting routines all in one subroutine. \"\"\"\n",
    "    try:\n",
    "        radar = pyart.io.read(radar_file_path)\n",
    "    except TypeError:\n",
    "        print(radar_file_path + ' has encountered TypeError!')\n",
    "        return\n",
    "\n",
    "    \n",
    "    radar_start_date = netCDF4.num2date(radar.time['data'][0],\n",
    "                                        radar.time['units'], \n",
    "                                        only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "    year_str = \"%04d\" % radar_start_date.year\n",
    "    month_str = \"%02d\" % radar_start_date.month\n",
    "    day_str = \"%02d\" % radar_start_date.day\n",
    "    hour_str = \"%02d\" % radar_start_date.hour\n",
    "    minute_str = \"%02d\" % radar_start_date.minute\n",
    "    second_str = \"%02d\" % radar_start_date.second\n",
    "    save_name = cmac_config['save_name']\n",
    "    file_name = (out_path + year_str + month_str + '/' + save_name + '.'\n",
    "                 + year_str + month_str + day_str + '.' + hour_str\n",
    "                 + minute_str + second_str + '.nc')\n",
    "    if os.path.exists(file_name):\n",
    "        del radar\n",
    "        return\n",
    "    rad_time = datetime.strptime(radar.time[\"units\"][0:33], \"seconds since %Y-%m-%d %H:%M:%S\")\n",
    "    # Load clutter files.\n",
    "    clutter = pyart.io.read(\n",
    "        clutter_file_path+'clutter_corcsapr2cfrppiM1.a1'\n",
    "        + '.' + year_str + month_str + day_str + '.' + hour_str\n",
    "        + minute_str + second_str + '.nc')\n",
    "    clutter_field_dict = clutter.fields['ground_clutter']\n",
    "    radar.add_field(\n",
    "        'ground_clutter', clutter_field_dict, replace_existing=True)\n",
    "    del clutter\n",
    "    sonde_index = np.argmin(np.abs(sonde_times - rad_time))\n",
    "    sounding_file = sounding_files[sonde_index]\n",
    "    # Retrieve closest sonde in time to the time of the radar file.\n",
    "    sonde = netCDF4.Dataset(sounding_file)\n",
    "    # Running the cmac code to produce a cmac_radar object.\n",
    "    try:\n",
    "        cmac_radar = cmac(radar, sonde, 'cacti_csapr2_ppi')\n",
    "    except ValueError:\n",
    "        del radar\n",
    "        sonde.close()\n",
    "        return\n",
    "    # Free up some memory.\n",
    "    del radar\n",
    "    sonde.close()\n",
    "\n",
    "    # Produce the cmac_radar file from the cmac_radar object.\n",
    "    pyart.io.write_cfradial(file_name, cmac_radar)\n",
    "    print('## A CMAC radar object has been created at ' + file_name)\n",
    "\n",
    "    if not os.path.exists(img_directory):\n",
    "        os.makedirs(img_directory)\n",
    "        subprocess.call('chmod -R g+rw ' + img_directory, shell=True)\n",
    "\n",
    "    # Producing all the cmac_radar quicklooks.\n",
    "    quicklooks(cmac_radar, 'cacti_csapr2_ppi',\n",
    "               dd_lobes=False, image_directory=img_directory)\n",
    "\n",
    "    # Delete the cmac_radar object and move on to the next radar file.\n",
    "    del cmac_radar\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function genericpath.exists(path)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to start our dask cluster. Normally, the script to do this on stratus is in qsub_xsapr. The dask-scheduler has to be running on one compute node and the dask-workers on the other computer nodes. However, since we are only on one node, we can just use multiprocessing to do our work for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMAC2.0 has different dictionaries that specify various configurations for the 3 XSAPRs in SGP. Here we will load i5 since the demo data is from XSAPR i5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_config = config.get_metadata('cacti_csapr2_ppi')\n",
    "cmac_config = config.get_cmac_values('cacti_csapr2_ppi')\n",
    "field_config = config.get_field_names('cacti_csapr2_ppi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use a dask bag to map the radar list into distributed memory and then execute the processing code on each file using .map().compute() on the bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundings_directory = '/lustre/or-hydra/cades-arm/proj-shared/corsondewnpnM1.b1/'\n",
    "radar_directory = '/lustre/or-hydra/cades-arm/proj-shared/corcsapr2cfrppiM1.a1/'\n",
    "clutter_directory = '/lustre/or-hydra/cades-arm/proj-shared/csapr2_clutter/'\n",
    "radar_files = glob(radar_directory + '*/*', recursive=True)\n",
    "sounding_files = glob(soundings_directory + '*')\n",
    "#clutter_files = glob(clutter_directory)\n",
    "\n",
    "img_directory = '/lustre/or-hydra/cades-arm/proj-shared/cacticsapr2cmacppi.c1.png'\n",
    "out_path = '/lustre/or-hydra/cades-arm/proj-shared/cacticsapr2cmacppi.c1/'\n",
    "log_path = '/lustre/or-hydra/cades-arm/proj-shared/csapr_log/'\n",
    "#sonde_file = '/home/rjackson/i5_test_data/sgpsondewnpnC1.b1.20170926.113600.cdf'\n",
    "#clutter_file_path = '/home/rjackson/clutter201709.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_files.sort()\n",
    "sounding_files.sort()\n",
    "#clutter_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sonde_times(file_list):\n",
    "    time_list = []\n",
    "    for name in file_list:\n",
    "        time_list.append(datetime.strptime(name.split('/')[-1], 'corsondewnpnM1.b1.%Y%m%d.%H%M%S.cdf'))\n",
    "    return np.array(time_list)\n",
    "        \n",
    "#def parse_clutter_times(file_list):\n",
    " #   time_list = []\n",
    "  #  for name in file_list:\n",
    "   #     time_list.append(datetime.strptime(name.split('/')[-1], 'clutter_corcsapr2cfrppiM1.a1.%Y%m%d.%H%M%S.nc'))\n",
    "    #return np.array(time_list)\n",
    "\n",
    "sonde_times = parse_sonde_times(sounding_files)\n",
    "#clutter_times = parse_clutter_times(clutter_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clutter_times.sort()\n",
    "sonde_times.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7732"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(radar_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_file = radar_files[0]\n",
    "radar = pyart.io.read(rad_file)\n",
    "rad_time = datetime.strptime(radar.time[\"units\"][0:33], \"seconds since %Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonde_index = np.argmin(np.abs(sonde_times - rad_time))\n",
    "sounding_file = sounding_files[sonde_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutter_index = np.argmin(np.abs(clutter_times - rad_time))\n",
    "clutter_file = clutter_files[clutter_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sounding_file)\n",
    "print(clutter_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmac_from_index(rad_file):\n",
    "    radar = pyart.io.read(rad_file)\n",
    "    rad_time = datetime.strptime(radar.time[\"units\"][0:33], \"seconds since %Y-%m-%d %H:%M:%S\")\n",
    "    del radar\n",
    "    sonde_index = np.argmin(np.abs(sonde_times - rad_time))\n",
    "    sounding_file = sounding_files[sonde_index]\n",
    "    clutter_file = clutter_files[i]\n",
    "    \n",
    "    #f= open(os.path.join(log_path,\"{0}.txt\".format(str(i).zfill(4))),\"w+\")\n",
    "    #f.write('Radar file: {0}\\n'.format(rad_file))\n",
    "    #f.write('Sounding file: {0}\\n'.format(sounding_file))\n",
    "    #f.write('Clutter file: {0}\\n'.format(clutter_file))\n",
    "    #f.close()\n",
    "    print(rad_file)\n",
    "    print(clutter_file)\n",
    "    run_cmac_and_plotting(rad_file, 'cacti_csapr2_ppi',\n",
    "                          sounding_file, clutter_file, \n",
    "                          out_path, img_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster = PBSCluster(name='dask-worker', memory='270GB', cores=36, processes=6, interface='ib0', queue='high_mem', project='arm',\n",
    "#                    walltime='00:30:00')#, job-extra=['-W group_list=cades-arm'])\n",
    "cluster1 = PBSCluster(processes=9, cores=36, walltime='14:00:00', memory='160GB',\n",
    "                      name='dask-worker', interface='ib0', queue='arm_high_mem', project='arm',\n",
    "                      job_extra=['-W group_list=cades-arm'])\n",
    "cluster1.scale(4*9)         # Ask for ten workers\n",
    "client1 = Client(cluster1)  # Connect this local process to remote workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.23.216.81:42021</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.23.216.81:8787/status' target='_blank'>http://10.23.216.81:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>36</li>\n",
       "  <li><b>Cores: </b>144</li>\n",
       "  <li><b>Memory: </b>640.08 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.23.216.81:42021' processes=36 threads=144, memory=640.08 GB>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_bag = db.from_sequence(radar_files)\n",
    "the_function = lambda x: run_cmac_and_plotting(x, cmac_config, sonde_times,\n",
    "                      sounding_files, clutter_directory, \n",
    "                      out_path, img_directory, sweep=3, dd_lobes=False)\n",
    "\n",
    "futures1 = the_bag.map(the_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "progress(futures1.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qdel: Request invalid for state of job MSG=invalid state for job - COMPLETE 876791.or-condo-pbs01\r\n",
      "qdel: Request invalid for state of job MSG=invalid state for job - COMPLETE 876792.or-condo-pbs01\r\n",
      "qdel: Request invalid for state of job MSG=invalid state for job - COMPLETE 876793.or-condo-pbs01\r\n",
      "qdel: Request invalid for state of job MSG=invalid state for job - COMPLETE 876794.or-condo-pbs01\r\n"
     ]
    }
   ],
   "source": [
    "!qselect -u zsherman | xargs qdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cmac_and_plotting(radar_files[0], cmac_config, sonde_times,\n",
    "                      sounding_files, clutter_directory, \n",
    "                      out_path, img_directory, sweep=3, dd_lobes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_file = radar_files[540]\n",
    "radar = pyart.io.read(rad_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_time = datetime.strptime(radar.time[\"units\"][0:33], \"seconds since %Y-%m-%d %H:%M:%S\")\n",
    "sonde_index = np.argmin(np.abs(sonde_times - rad_time))\n",
    "sounding_file = sounding_files[sonde_index]\n",
    "clutter_index = np.argmin(np.abs(clutter_times - rad_time))\n",
    "clutter_file = clutter_files[clutter_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutter = pyart.io.read(clutter_file)\n",
    "clutter_field_dict = clutter.fields['ground_clutter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutter_field_dict['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in radar.fields.keys():\n",
    "    print(radar.fields[key]['data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHY am i getting an invalid shape error? Where is the shape (5402,1110) coming from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_files = glob('/home/rjackson/xsapr_imgs/reflectivity*.png')\n",
    "# im_files.sort()\n",
    "# images = []\n",
    "# for filename in im_files:\n",
    "#     images.append(imageio.imread(filename))\n",
    "# imageio.mimsave('refl_animation.gif', images, duration=0.5)\n",
    "\n",
    "# with open('refl_animation.gif','rb') as f:\n",
    "#     display(Image(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_files = glob('/lcrc/group/earthscience/icrisologo/csapr_imgs/masked_corrected_reflectivity*.png')\n",
    "im_files.sort()\n",
    "images = []\n",
    "for filename in im_files:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('refl_animation.gif', images, duration=0.5)\n",
    "\n",
    "with open('refl_animation.gif','rb') as f:\n",
    "    display(Image(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
